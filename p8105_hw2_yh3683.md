p8105_hw2_yh3683
================
Yining He
2024-10-01

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.1     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.3     ✔ tidyr     1.3.1
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(dplyr)
library(readxl)
library(janitor)
```

    ## 
    ## Attaching package: 'janitor'
    ## 
    ## The following objects are masked from 'package:stats':
    ## 
    ##     chisq.test, fisher.test

# Problem 1

``` r
nyc_subway_data = read_csv("NYC_Transit_Subway_Entrance_And_Exit_Data.csv")
```

    ## Rows: 1868 Columns: 32
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (22): Division, Line, Station Name, Route1, Route2, Route3, Route4, Rout...
    ## dbl  (8): Station Latitude, Station Longitude, Route8, Route9, Route10, Rout...
    ## lgl  (2): ADA, Free Crossover
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
nyc_subway_data =janitor::clean_names(nyc_subway_data)

colnames(nyc_subway_data)
```

    ##  [1] "division"           "line"               "station_name"      
    ##  [4] "station_latitude"   "station_longitude"  "route1"            
    ##  [7] "route2"             "route3"             "route4"            
    ## [10] "route5"             "route6"             "route7"            
    ## [13] "route8"             "route9"             "route10"           
    ## [16] "route11"            "entrance_type"      "entry"             
    ## [19] "exit_only"          "vending"            "staffing"          
    ## [22] "staff_hours"        "ada"                "ada_notes"         
    ## [25] "free_crossover"     "north_south_street" "east_west_street"  
    ## [28] "corner"             "entrance_latitude"  "entrance_longitude"
    ## [31] "station_location"   "entrance_location"

``` r
cleaned_data <- nyc_subway_data %>%
  select(line, station_name, station_latitude, station_longitude, route1, route2, route3, route4, route5, route6, route7, entry, vending, entrance_type, ada) %>%
  mutate(
    entry = ifelse(entry == "YES", TRUE, FALSE)  
  )
```

``` r
view(cleaned_data)
```

#### Describe about the cleaned dataset:

The dataset contains NYC subway station information, including line,
station name, latitude/longitude, routes(Route1-Route7), entry status,
vending, entrance type, and ADA compliance.

Data cleaning involved standardizing column names, selecting relevant
variables, and converting the entry variable to a logical TRUE/FALSE
format. The cleaned dataset has 1,868 rows and 15 columns, and with each
row representing a unique station entrance or exit.\*\*

But I don’t think is tidy enough, because it still have many missing
data (NA).

The number of distinct stations are 465

There are 84 ADA compliant stations.

The proportion of station entrances / exits without vending allow
entrance is about 0.3770492.

#### reform the data

``` r
reformatted_data <- cleaned_data %>%
  pivot_longer(cols = starts_with("route"), 
               names_to = "route_number", 
               values_to = "route_name") %>%
  filter(!is.na(route_name)) 
```

There are 60 distinct stations serve the A train

There are 17 stations that serve the A train are ADA compliant.

# Problem 2

#### clean the Mr. Trash Wheel sheet

``` r
mr_trash_wheel_data <- read_excel("202409 Trash Wheel Collection Data.xlsx", 
                                  sheet = 1,   
                                  skip = 1) %>%  
  janitor::clean_names()  
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

``` r
colnames(mr_trash_wheel_data)
```

    ##  [1] "dumpster"           "month"              "year"              
    ##  [4] "date"               "weight_tons"        "volume_cubic_yards"
    ##  [7] "plastic_bottles"    "polystyrene"        "cigarette_butts"   
    ## [10] "glass_bottles"      "plastic_bags"       "wrappers"          
    ## [13] "sports_balls"       "homes_powered"      "x15"               
    ## [16] "x16"

``` r
mr_trash_wheel_data <- mr_trash_wheel_data %>%
  filter(!is.na(dumpster))

mr_trash_wheel_data <- mr_trash_wheel_data %>%
  mutate(sports_balls = as.integer(round(sports_balls)))
mr_trash_wheel_data <- mr_trash_wheel_data %>%
  select(-x15, -x16)

view(mr_trash_wheel_data)
```

#### clean theProfessor Trash Wheel sheet

``` r
#import data file
professor_trash_wheel_data <- read_excel("202409 Trash Wheel Collection Data.xlsx", 
                                         sheet = 2,   
                                         skip = 1) %>%  
  janitor::clean_names()  

colnames(professor_trash_wheel_data)
```

    ##  [1] "dumpster"           "month"              "year"              
    ##  [4] "date"               "weight_tons"        "volume_cubic_yards"
    ##  [7] "plastic_bottles"    "polystyrene"        "cigarette_butts"   
    ## [10] "glass_bottles"      "plastic_bags"       "wrappers"          
    ## [13] "homes_powered"

``` r
professor_trash_wheel_data <- professor_trash_wheel_data %>%
  filter(!is.na(dumpster))

view(professor_trash_wheel_data)

#no sports balls column
```

#### clean the gwynnda_trash_wheel Wheel sheet

``` r
gwynnda_trash_wheel_data <- read_excel("202409 Trash Wheel Collection Data.xlsx", 
                                       sheet = 4,   
                                       skip = 1) %>%  
  janitor::clean_names()  
colnames(gwynnda_trash_wheel_data)
```

    ##  [1] "dumpster"           "month"              "year"              
    ##  [4] "date"               "weight_tons"        "volume_cubic_yards"
    ##  [7] "plastic_bottles"    "polystyrene"        "cigarette_butts"   
    ## [10] "plastic_bags"       "wrappers"           "homes_powered"

``` r
gwynnda_trash_wheel_data <- gwynnda_trash_wheel_data %>%
  filter(!is.na(dumpster))

view(gwynnda_trash_wheel_data)

#no sports_balls and glass bottles
```

#### creat a new data sheet

If we want to make a new table i should add a “sports_ball” column in
professor_trash_wheel_data table and add “lass_bottles” “sports_balls”
in gwynnda_trash_wheel_data table.

``` r
mr_trash_wheel_data <- mr_trash_wheel_data %>%
  mutate(year = as.character(year))

professor_trash_wheel_data <- professor_trash_wheel_data %>%
  mutate(year = as.character(year))

gwynnda_trash_wheel_data <- gwynnda_trash_wheel_data %>%
  mutate(year = as.character(year))

professor_trash_wheel_data <- professor_trash_wheel_data %>%
  mutate(sports_balls = NA)

gwynnda_trash_wheel_data <- gwynnda_trash_wheel_data %>%
  mutate(glass_bottles = NA, sports_balls = NA)

combined_trash_wheel_data <- bind_rows(mr_trash_wheel_data, professor_trash_wheel_data, gwynnda_trash_wheel_data)

view(combined_trash_wheel_data)
```

Description of the new dataset:

The combined_trash_wheel_data combines data from the three sources:
Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda Trash Wheel. The
dataset contains1033 rows and 14 columns. Key variables in the dataset
include weight_tons, which records the weight of trash collected in
tons, and volume_cubic_yards, representing the volume of trash collected
in cubic yards. Additionally, the dataset contains variables like
plastic_bottles (number of plastic bottles collected), cigarette_butts,
and sports_balls, though some columns such as sports_balls and
glass_bottles were missing from certain sources and have been filled
with NA values where applicable.The variables sports_balls and
glass_bottles were added to datasets that didn’t originally have them,
with missing data represented as NA.

The total weight is 246.74 tons.

The total number of cigatette butts is 18120 butts.

# Problem3

Delete the first two lines of results,csv and show all the columns name.

``` r
results <- read.csv("results.csv", skip = 2)|> 
  janitor::clean_names()
bakes <- read.csv("bakes.csv")|>
  janitor::clean_names()
bakers <- read.csv("bakers.csv")|>
  janitor::clean_names()

colnames(results)
```

    ## [1] "series"    "episode"   "baker"     "technical" "result"

``` r
colnames(bakes)
```

    ## [1] "series"         "episode"        "baker"          "signature_bake"
    ## [5] "show_stopper"

``` r
colnames(bakers)
```

    ## [1] "baker_name"       "series"           "baker_age"        "baker_occupation"
    ## [5] "hometown"

These lines of R code use the mutate() function to ensure that specific
columns in the results, bakes, and bakers datasets are converted to the
character data type and have consistent names for merging.

``` r
results <- results |> setNames(c("series", "episode", "baker", "technical", "result")) #rename the variables of results and make them consist with other two fies.

bakes <- bakes |>
  mutate(series = as.numeric(series), episode = as.numeric(episode))

results <- results |>
  mutate(series = as.numeric(series), episode = as.numeric(episode))

bakers <- bakers |>
  mutate(baker = baker_name) |>
  mutate(series = as.numeric(series))

#change to first name
bakers <- bakers |>
  mutate(baker = word(baker, 1))
```

``` r
#check for completeness and correctness across datasets (e.g. by viewing individual datasets and using anti_join
REBE <- anti_join(results, bakers, by = c("series", "baker")) |> nrow()
BERE <- anti_join(bakers, results, by = c("series", "baker")) |> nrow()
REBE
```

    ## [1] 8

``` r
BERE
```

    ## [1] 1

``` r
# we can merge the bakers and results first , because there are too many missing data in bakes file.

bakeresults <- results |>
  left_join(bakers, by = c("series", "baker"))

view(bakeresults)
```

``` r
# we will merge the bakes table with bakeresults table and make it in meaningful orders.
final_data <- bakeresults |>
  left_join(bakes, by = c("series", "episode", "baker")) |>
  select(series, episode, baker, baker_age, baker_occupation, hometown, 
         signature_bake, show_stopper, technical, result) |>
  arrange(series, episode, baker)

view(final_data)

write_csv(final_data, "final_data.csv")
```

Describe your data cleaning process: In the data cleaning process, we
started by importing the results, bakes, and bakers datasets, deleting
the first two rows of results.csv, and using janitor::clean_names() to
standardize column names. We ensured consistency across the datasets by
converting series and episode columns to numeric and renaming the baker
column in bakers to match the others. We also extracted first names from
the baker column to ensure uniformity across datasets. To check for
completeness, we used anti_join() to identify unmatched records between
results and bakers. After confirming the data consistency, we merged
results with bakers and then merged the result with bakes, selecting
relevant columns and sorting the final dataset by series, episode, and
baker for meaningful organization. Finally, the cleaned dataset was
saved as final_data.csv.

Question: However, I encountered several issues during the data cleaning
process. For example, after using mutate(), an extra column baker_name
appeared, or when I didn’t apply janitor::clean_names() initially, the
Hometown and Occupation columns showed as NA.

Briefly discuss the final dataset: The final dataset merges information
have 1136 entries and 10 columns,which includes bakers, episodes, and
their performance. It organizes bakers’ demographic data (age,
occupation, hometown) along with their performance data from different
baking challenges. The dataset still have some misssing values in
different columns.

#### create a reader-friendly table

``` r
final_data <- final_data %>%
  mutate(result = str_trim(result)) %>% 
  filter(result %in% c("Star Baker", "Winner", "STAR BAKER", "WINNER"))

star_bakers_winners <- final_data %>%
  filter(series >= 5 & series <= 10) %>%
  arrange(series, episode) %>%
  select(series, episode, baker, baker_age, baker_occupation, hometown, signature_bake, show_stopper, technical, result)

view(star_bakers_winners)
```

``` r
hometown_star_baker <- star_bakers_winners %>%
  filter(result %in% c("Star Baker", "STAR BAKER")) %>% 
  count(hometown, sort = TRUE) %>% 
  slice_max(n = 1, order_by = n)
hometown_star_baker
```

    ##            hometown n
    ## 1            London 5
    ## 2 Mill Hill, London 5

We found that most of the Star Bakers are from London, but there isn’t a
single winner from there.

``` r
winners_table <- star_bakers_winners %>%
  mutate(result = str_trim(result)) %>% 
  filter(result %in% c("Winner", "WINNER")) %>%  
  select(series, episode, baker, baker_age, baker_occupation, hometown, signature_bake, show_stopper, result)
winners_table
```

    ##   series episode   baker baker_age                           baker_occupation
    ## 1      5      10   Nancy        60                   Retired Practice Manager
    ## 2      6      10  Nadiya        30                           Full-time mother
    ## 3      7      10 Candice        31                                 PE teacher
    ## 4      8      10  Sophie        33 Former army officer and trainee stuntwoman
    ## 5      9      10   Rahul        30                         Research scientist
    ## 6     10      10   David        36               International health adviser
    ##                           hometown
    ## 1 Barton-upon-Humber, Lincolnshire
    ## 2                    Leeds / Luton
    ## 3     Barton-Le-Clay, Bedfordshire
    ## 4             West Molesey, Surrey
    ## 5                        Rotherham
    ## 6                           Whitby
    ##                                               signature_bake
    ## 1       Apple and Lemon KitesRaspberry and Almond Croissants
    ## 2  Cardamom and Almond Buns & Nutmeg and Sour Cherry Fingers
    ## 3                Queen Victoria's Mango and Strawberry Crown
    ## 4 Spelt Boules, Mushroom Ciabatta and Orange Plaited Brioche
    ## 5                                                       <NA>
    ## 6                                                       <NA>
    ##                         show_stopper result
    ## 1                       Red Windmill WINNER
    ## 2    My Big Fat British Wedding Cake WINNER
    ## 3 Picnic for Pearly Kings and Queens WINNER
    ## 4    'Ode to the Honey Bee' Entremet WINNER
    ## 5                               <NA> WINNER
    ## 6                               <NA> WINNER

Through observing all the winners from Seasons 5 to 10, most of the
winners were female, with the majority falling within the 30-40 age
range. However, their professions were quite surprising, coming from
various industries, including a PE teacher and an international health
adviser. I think it’s still quite difficult to predict the winner.

#### viewership

``` r
viewers <- read.csv("viewers.csv")|>
  janitor::clean_names()
colnames(viewers)
```

    ##  [1] "episode"   "series_1"  "series_2"  "series_3"  "series_4"  "series_5" 
    ##  [7] "series_6"  "series_7"  "series_8"  "series_9"  "series_10"

``` r
head(viewers, 10)
```

    ##    episode series_1 series_2 series_3 series_4 series_5 series_6 series_7
    ## 1        1     2.24     3.10     3.85     6.60    8.510    11.62    13.58
    ## 2        2     3.00     3.53     4.60     6.65    8.790    11.59    13.45
    ## 3        3     3.00     3.82     4.53     7.17    9.280    12.01    13.01
    ## 4        4     2.60     3.60     4.71     6.82   10.250    12.36    13.29
    ## 5        5     3.03     3.83     4.61     6.95    9.950    12.39    13.12
    ## 6        6     2.75     4.25     4.82     7.32   10.130    12.00    13.13
    ## 7        7       NA     4.42     5.10     7.76   10.280    12.35    13.45
    ## 8        8       NA     5.06     5.35     7.41    9.023    11.09    13.26
    ## 9        9       NA       NA     5.70     7.41   10.670    12.65    13.44
    ## 10      10       NA       NA     6.74     9.45   13.510    15.05    15.90
    ##    series_8 series_9 series_10
    ## 1      9.46     9.55      9.62
    ## 2      9.23     9.31      9.38
    ## 3      8.68     8.91      8.94
    ## 4      8.55     8.88      8.96
    ## 5      8.61     8.67      9.26
    ## 6      8.61     8.91      8.70
    ## 7      9.01     9.22      8.98
    ## 8      8.95     9.69      9.19
    ## 9      9.03     9.50      9.34
    ## 10    10.04    10.34     10.05

The average viewership in Season 1 is 2.77.

The average viewership in Season 5 is 10.0393.
