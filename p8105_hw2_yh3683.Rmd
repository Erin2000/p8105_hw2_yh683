---
title: "p8105_hw2_yh3683"
author: "Yining He"
date: "2024-10-01"
output: github_document
---

```{r}
library(tidyverse)
library(dplyr)
library(readxl)
library(janitor)

```


# Problem 1
```{r}
nyc_subway_data = read_csv("NYC_Transit_Subway_Entrance_And_Exit_Data.csv")

nyc_subway_data =janitor::clean_names(nyc_subway_data)

colnames(nyc_subway_data)

cleaned_data <- nyc_subway_data %>%
  select(line, station_name, station_latitude, station_longitude, route1, route2, route3, route4, route5, route6, route7, entry, vending, entrance_type, ada) %>%
  mutate(
    entry = ifelse(entry == "YES", TRUE, FALSE)  
  )
```

```{r}
view(cleaned_data)
```
#### Describe about the cleaned dataset:
The dataset contains NYC subway station information, including line, station name, latitude/longitude, routes(Route1-Route7), entry status, vending, entrance type, and ADA compliance.

Data cleaning involved standardizing column names, selecting relevant variables, and converting the entry variable to a logical TRUE/FALSE format. The cleaned dataset has 1,868 rows and 15 columns, and with each row representing a unique station entrance or exit.**

But I don't think is tidy enough, because it still have many missing data (NA).

```{r include=FALSE}
distinct_stations <- cleaned_data %>% 
  distinct(station_name, line) 
n_distinct_stations <- nrow(distinct_stations)
```
The number of distinct stations are `r n_distinct_stations `

```{r include=FALSE}
ada_compliant_stations <- cleaned_data %>%
  filter(ada == TRUE) %>%
  distinct(station_name, line)

n_ada_compliant_stations <- nrow(ada_compliant_stations)
```
There are `r n_ada_compliant_stations` ADA compliant stations.


```{r include=FALSE}
no_vending_entrances <- cleaned_data %>%
  filter(vending == "NO")
proportion_allowing_entrance <- mean(no_vending_entrances$entry)
```
The proportion of station entrances / exits without vending allow entrance is about `r proportion_allowing_entrance`.

#### reform the data
```{r}
reformatted_data <- cleaned_data %>%
  pivot_longer(cols = starts_with("route"), 
               names_to = "route_number", 
               values_to = "route_name") %>%
  filter(!is.na(route_name)) 

```

```{r include=FALSE}
a_train_stations <- reformatted_data %>%
  filter(route_name == "A") %>%
  distinct(station_name, line)
n_a_train_stations <- nrow(a_train_stations)
```
There are `r n_a_train_stations` distinct stations serve the A train

```{r include=FALSE}
# Filter for ADA-compliant stations that serve the A train
ada_a_train_stations <- reformatted_data %>%
  filter(route_name == "A", ada == TRUE) %>%
  distinct(station_name, line)
n_ada_a_train_stations <- nrow(ada_a_train_stations)
```
There are `r n_ada_a_train_stations` stations that serve the A train are ADA compliant.

# Problem 2

#### clean the Mr. Trash Wheel sheet

```{r}

mr_trash_wheel_data <- read_excel("202409 Trash Wheel Collection Data.xlsx", 
                                  sheet = 1,   
                                  skip = 1) %>%  
  janitor::clean_names()  

colnames(mr_trash_wheel_data)

mr_trash_wheel_data <- mr_trash_wheel_data %>%
  filter(!is.na(dumpster))

mr_trash_wheel_data <- mr_trash_wheel_data %>%
  mutate(sports_balls = as.integer(round(sports_balls)))
mr_trash_wheel_data <- mr_trash_wheel_data %>%
  select(-x15, -x16)

view(mr_trash_wheel_data)
```


#### clean theProfessor Trash Wheel sheet
```{r}
#import data file
professor_trash_wheel_data <- read_excel("202409 Trash Wheel Collection Data.xlsx", 
                                         sheet = 2,   
                                         skip = 1) %>%  
  janitor::clean_names()  

colnames(professor_trash_wheel_data)

professor_trash_wheel_data <- professor_trash_wheel_data %>%
  filter(!is.na(dumpster))

view(professor_trash_wheel_data)

#no sports balls column
```

#### clean the gwynnda_trash_wheel Wheel sheet

```{r}
gwynnda_trash_wheel_data <- read_excel("202409 Trash Wheel Collection Data.xlsx", 
                                       sheet = 4,   
                                       skip = 1) %>%  
  janitor::clean_names()  
colnames(gwynnda_trash_wheel_data)
gwynnda_trash_wheel_data <- gwynnda_trash_wheel_data %>%
  filter(!is.na(dumpster))

view(gwynnda_trash_wheel_data)

#no sports_balls and glass bottles
```
#### creat a new data sheet

If we want to make a new table i should add a "sports_ball" column in professor_trash_wheel_data table and add "lass_bottles" "sports_balls" in gwynnda_trash_wheel_data table.

```{r}
mr_trash_wheel_data <- mr_trash_wheel_data %>%
  mutate(year = as.character(year))

professor_trash_wheel_data <- professor_trash_wheel_data %>%
  mutate(year = as.character(year))

gwynnda_trash_wheel_data <- gwynnda_trash_wheel_data %>%
  mutate(year = as.character(year))

professor_trash_wheel_data <- professor_trash_wheel_data %>%
  mutate(sports_balls = NA)

gwynnda_trash_wheel_data <- gwynnda_trash_wheel_data %>%
  mutate(glass_bottles = NA, sports_balls = NA)

combined_trash_wheel_data <- bind_rows(mr_trash_wheel_data, professor_trash_wheel_data, gwynnda_trash_wheel_data)

view(combined_trash_wheel_data)

```

Description of the new dataset:

The combined_trash_wheel_data combines data from the three sources: Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda Trash Wheel. 
The dataset contains`r nrow(combined_trash_wheel_data)` rows and `r ncol(combined_trash_wheel_data)` columns.
Key variables in the dataset include weight_tons, which records the weight of trash collected in tons, and volume_cubic_yards, representing the volume of trash collected in cubic yards. Additionally, the dataset contains variables like plastic_bottles (number of plastic bottles collected), cigarette_butts, and sports_balls, though some columns such as sports_balls and glass_bottles were missing from certain sources and have been filled with NA values where applicable.The variables sports_balls and glass_bottles were added to datasets that didn’t originally have them, with missing data represented as NA.

```{r include=FALSE}
total_weight_professor <- professor_trash_wheel_data %>%
  summarise(total_weight_tons = sum(weight_tons, na.rm = TRUE))
```
The total weight is `r total_weight_professor` tons.

```{r include=FALSE}
options(scipen = 999)
total_cigarette_butts_gwynnda_june_2022 <- gwynnda_trash_wheel_data %>%
  filter(month == "June", year == "2022") %>%
  summarise(total_cigarette_butts = sum(cigarette_butts, na.rm = TRUE))
```
The total number of cigatette butts is `r total_cigarette_butts_gwynnda_june_2022` butts.



# Problem3

Delete the first two lines of results,csv and show all the columns name.
```{r}
results <- read.csv("results.csv", skip = 2)|> 
  janitor::clean_names()
bakes <- read.csv("bakes.csv")|>
  janitor::clean_names()
bakers <- read.csv("bakers.csv")|>
  janitor::clean_names()

colnames(results)
colnames(bakes)
colnames(bakers)
```
These lines of R code use the mutate() function to ensure that specific columns in the results, bakes, and bakers datasets are converted to the character data type and have consistent names for merging.
```{r}
results <- results |> setNames(c("series", "episode", "baker", "technical", "result")) #rename the variables of results and make them consist with other two fies.

bakes <- bakes |>
  mutate(series = as.numeric(series), episode = as.numeric(episode))

results <- results |>
  mutate(series = as.numeric(series), episode = as.numeric(episode))

bakers <- bakers |>
  mutate(baker = baker_name) |>
  mutate(series = as.numeric(series))

#change to first name
bakers <- bakers |>
  mutate(baker = word(baker, 1))
```



```{r}
#check for completeness and correctness across datasets (e.g. by viewing individual datasets and using anti_join
REBE <- anti_join(results, bakers, by = c("series", "baker")) |> nrow()
BERE <- anti_join(bakers, results, by = c("series", "baker")) |> nrow()
REBE
BERE
```
```{r}
# we can merge the bakers and results first , because there are too many missing data in bakes file.

bakeresults <- results |>
  left_join(bakers, by = c("series", "baker"))

view(bakeresults)
```

```{r}
# we will merge the bakes table with bakeresults table and make it in meaningful orders.
final_data <- bakeresults |>
  left_join(bakes, by = c("series", "episode", "baker")) |>
  select(series, episode, baker, baker_age, baker_occupation, hometown, 
         signature_bake, show_stopper, technical, result) |>
  arrange(series, episode, baker)

view(final_data)

write_csv(final_data, "final_data.csv")
```

Describe your data cleaning process:
In the data cleaning process, we started by importing the results, bakes, and bakers datasets, deleting the first two rows of results.csv, and using janitor::clean_names() to standardize column names. We ensured consistency across the datasets by converting series and episode columns to numeric and renaming the baker column in bakers to match the others. We also extracted first names from the baker column to ensure uniformity across datasets. To check for completeness, we used anti_join() to identify unmatched records between results and bakers. After confirming the data consistency, we merged results with bakers and then merged the result with bakes, selecting relevant columns and sorting the final dataset by series, episode, and baker for meaningful organization. Finally, the cleaned dataset was saved as final_data.csv.

Question:
However, I encountered several issues during the data cleaning process. For example, after using mutate(), an extra column baker_name appeared, or when I didn’t apply janitor::clean_names() initially, the Hometown and Occupation columns showed as NA.

Briefly discuss the final dataset:
The final dataset merges information have 1136 entries and 10 columns,which includes bakers, episodes, and their performance. It organizes bakers' demographic data (age, occupation, hometown) along with their performance data from different baking challenges. The dataset still have some misssing values in different columns.

#### create a reader-friendly table 

```{r}
final_data <- final_data %>%
  mutate(result = str_trim(result)) %>% 
  filter(result %in% c("Star Baker", "Winner", "STAR BAKER", "WINNER"))

star_bakers_winners <- final_data %>%
  filter(series >= 5 & series <= 10) %>%
  arrange(series, episode) %>%
  select(series, episode, baker, baker_age, baker_occupation, hometown, signature_bake, show_stopper, technical, result)

view(star_bakers_winners)
```

```{r}
hometown_star_baker <- star_bakers_winners %>%
  filter(result %in% c("Star Baker", "STAR BAKER")) %>% 
  count(hometown, sort = TRUE) %>% 
  slice_max(n = 1, order_by = n)
hometown_star_baker
```
We found that most of the Star Bakers are from London, but there isn't a single winner from there.

```{r}
winners_table <- star_bakers_winners %>%
  mutate(result = str_trim(result)) %>% 
  filter(result %in% c("Winner", "WINNER")) %>%  
  select(series, episode, baker, baker_age, baker_occupation, hometown, signature_bake, show_stopper, result)
winners_table
```
Through observing all the winners from Seasons 5 to 10, most of the winners were female, with the majority falling within the 30-40 age range. However, their professions were quite surprising, coming from various industries, including a PE teacher and an international health adviser. I think it's still quite difficult to predict the winner.


#### viewership
```{r}
viewers <- read.csv("viewers.csv")|>
  janitor::clean_names()
colnames(viewers)
head(viewers, 10)
```
The average viewership in Season 1 is `r mean(viewers$series_1,na.rm=T)`.

The average viewership in Season 5 is `r mean(viewers$series_5,na.rm=T)`.










 









